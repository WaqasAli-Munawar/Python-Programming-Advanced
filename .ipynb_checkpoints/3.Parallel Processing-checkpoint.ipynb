{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've seen how the CPU runs code in sequence, and how control flow statements (like if and else) can change the order in which it executes statements. However, we can also write programs that execute more than one instruction at a time. A multi-core CPU has the ability to run multiple instructions simultaneously. The desire to take advantage of modern, multi-core CPUs has given rise to a technique called **parallel processing**, which is very useful in data science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel processing can be powerful, but it also presents many unique challenges. When multiple processes are sharing data, it's important to manage which process has access to the data and when so that it doesn't become corrupted. It's also important to think the execution of parallel processes through carefully, because executing multiple instructions at once can potentially introduce tricky bugs. Learning to manage these factors will help us write very powerful code that does quick and meaningful data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, some values are immutable, such as integers. This means that we can't change them. Most of the data structures we've worked with (like dictionaries and lists) are **mutable**, so they're useful for representing information that changes. Mutable variables are especially useful in parallel processing because we often want to share and edit the same data between different processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter():\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "    def increment(self):\n",
    "        self.count += 1\n",
    "    def get_count(self):\n",
    "        return self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_up_100000(counter):\n",
    "    for i in range(100000):\n",
    "        counter.increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a mutable instance of the Counter class\n",
    "\n",
    "counter = Counter()\n",
    "initial_count = counter.get_count()\n",
    "count_up_100000(counter)\n",
    "final_count = counter.get_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(initial_count)\n",
    "final_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We counted from 0 to 100000 using a Counter instance. Creating this instance, calling the function, and incrementing the counter all happened in one process. Every instruction in the process executed one after the other. We can also run multiple processes at once, however. We often refer to this technique as **multithreading**.\n",
    "\n",
    "A thread is one path of execution in a program. We typically have one \"main thread\" that we think of as our single process program. We can also create new threads, though, and run them concurrently with the main thread. To do this in Python, we use the **threading module**. Specifically, we can use **threading.Thread()** to create an instance of the Thread class, which executes a given function as a separate process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a Thread instance that runs the count_up_100000 function with counter as an argument, we write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "counter = Counter()\n",
    "count_thread = threading.Thread(target=count_up_100000, args=[counter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we start the thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we \"join\" the thread so that when it's finished executing, it \"joins\" with the main thread by terminating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main thread will wait until the other thread has finished executing before moving past the thread.join() call. Waiting for a condition like the termination of a thread is called **blocking**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "after_join = counter.get_count()\n",
    "print(after_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In programming, we say that a program is **deterministic** if we can precisely predict its output for a particular input. Most single-threaded operations are deterministic because we can walk through the code for any input step by step, and predict the output.\n",
    "\n",
    "If we write a program that determines age based on birthday, for example, we should be able to precisely predict how it will behave for any given input. We'd be able to look through the program and determine what the computer will do at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now imagine that we ask our friend to count to 100000, and then call us back when he's finished. Being an unusually obedient friend, he starts to count. In this analogy, we're the main thread of the program, and our friend is another thread.\n",
    "\n",
    "Our friend's call telling us that he's finished is analogous to joining the thread. We know when he calls that the value of his \"counter\" will be 100000. We know that this is true from our activity on above code, when we measured the value of the counter after the two threads joined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now imagine that we call our friend a few hours after he started counting to ask what number he's on. He may be at 1000, or 10000, or 25392. It's impossible to know for sure, and this is analogous to measuring the value of our counter before we've joined the counting thread. We can't predict this value because we don't know how many iterations of the counting loop will have been executed at the time of our reading. When we can't reliably predict the outcome of running a piece of code, we call that code **nondeterministic**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's conduct a \"trial\" by writing a function that starts a new counter thread, then measures the counter's value in the middle of the thread's execution. We'll conduct three trials and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_trial():\n",
    "    counter = Counter()\n",
    "    count_thread = threading.Thread(target = count_up_100000, args = [counter])\n",
    "    count_thread.start()\n",
    "    intermediate_value = counter.get_count()\n",
    "    count_thread.join()\n",
    "    return intermediate_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23793\n",
      "12848\n",
      "18725\n"
     ]
    }
   ],
   "source": [
    "trial1 = conduct_trial()\n",
    "print(trial1)\n",
    "trial2 = conduct_trial()\n",
    "print(trial2)\n",
    "trial3 = conduct_trial()\n",
    "print(trial3)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multithreading is nondeterministic by nature, but there are ways to combat that nondeterminism. The easiest and most common way to make multithreading more predictable is through the use of **threading.Lock**. A **lock** is a way to conditionally block the execution of some threads. At any given time, we can think of a lock as being either **available** or **acquired**. A thread can acquire an available lock, but if a thread tries to acquire an acquired lock (that another thread is using), it will be blocked until that lock becomes available.\n",
    "\n",
    "Suppose we have two threads, A and B, and that both have access to an instance of **threading.Lock** called **lock**, and a **Counter** instance called **counter**:\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above counts from 0 to 100 by 2. Thread A gets the value of the count at some point during thread B's counting process. Before it can get the value, thread A tries acquiring a lock. If the lock is available, thread A will get the count, and then release the lock. If the lock is unavailable (because thread B has it), thread A will wait for the lock to become available before continuing and getting the count value.\n",
    "\n",
    "Without the lock, thread A might get the count at any value between 0 and 100. With the lock, however, thread A can only get an even count, because it can only access the counter variable after it has already been incremented twice in the current iteration of the for loop. The lock ensures that our main thread can only read our counter variable at multiples of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In below code, we'll use a lock to ensure that our main thread can only read our counter variable at multiples of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the inner for loop in count_up_100000 inside lock.acquire() and \n",
    "# lock.release() so that nobody can acquire the lock \n",
    "# unless the counter value is a multiple of 10.\n",
    "\n",
    "import threading\n",
    "\n",
    "def count_up_100000(counter, lock):\n",
    "    for i in range(10000):\n",
    "        lock.acquire()\n",
    "        for i in range(10):\n",
    "            counter.increment()\n",
    "        lock.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In conduct_trial(), wrap the call to counter.get_count() inside lock.acquire()\n",
    "# and lock.release() so that the main thread can only read the counter value \n",
    "# at multiples of 10.\n",
    "\n",
    "def conduct_trial():\n",
    "    counter = Counter()\n",
    "    lock = threading.Lock()\n",
    "    count_thread = threading.Thread(target = count_up_100000, \n",
    "                                    args = [counter, lock])\n",
    "    count_thread.start()\n",
    "    lock.acquire()\n",
    "    intermediate_value = counter.get_count()\n",
    "    lock.release()\n",
    "    count_thread.join()\n",
    "    return intermediate_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17870\n",
      "11290\n",
      "7690\n"
     ]
    }
   ],
   "source": [
    "trial1 = conduct_trial()\n",
    "print(trial1)\n",
    "trial2 = conduct_trial()\n",
    "print(trial2)\n",
    "trial3 = conduct_trial()\n",
    "print(trial3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose we want to count to 200000. We can do this in two stages:\n",
    "\n",
    "Increment counter 100000 times\n",
    "\n",
    "Increment counter 100000 times again\n",
    "\n",
    "This approach will produce interesting results because the operation will behave differently if we split it up among multiple threads. First, let's implement this behavior using only the main thread. Try to predict the outcome before running a code. Remember that we're implementing a single-threaded solution, so the outcome should be **deterministic**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_up_100000(counter):\n",
    "    for i in range(100000):\n",
    "        counter.increment()\n",
    "        \n",
    "counter = Counter()\n",
    "\n",
    "count_up_100000(counter)\n",
    "count_up_100000(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    }
   ],
   "source": [
    "final_count = counter.get_count()\n",
    "print(final_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's implement a multi-threaded implementation to count to 200000. We've defined a conduct_trial() function that counts to 200000 with two threads, each of which increments the counter 100000 times. It's important that both of the threads start at the same time, and are joined at the same time. For this experiment, we want the threads to execute in parallel so we can make observations about how they behave in parallel.\n",
    "\n",
    "We'll need to join the threads in such a way that they're executing at the same time. Then we'll conduct and print the results of three trials that check the final value of our counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_up_100000(counter):\n",
    "    for i in range(100000):\n",
    "        counter.increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_trial():\n",
    "    counter = Counter()\n",
    "    count_thread1 = threading.Thread(target = count_up_100000, args = [counter])\n",
    "    count_thread2 = threading.Thread(target = count_up_100000, args = [counter])\n",
    "    count_thread1.start()\n",
    "    count_thread2.start()\n",
    "    \n",
    "    count_thread1.join()\n",
    "    count_thread2.join()\n",
    "    \n",
    "    final_count = counter.get_count()\n",
    "    return final_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181538\n",
      "126831\n",
      "139475\n"
     ]
    }
   ],
   "source": [
    "trial1 = conduct_trial()\n",
    "print(trial1)\n",
    "trial2 = conduct_trial()\n",
    "print(trial2)\n",
    "trial3 = conduct_trial()\n",
    "print(trial3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An **atomic** operation is an operation that finishes executing before any other operation can occur, regardless of multithreading. Thus far, we've considered all operations to be atomic.\n",
    "\n",
    "On the above code, we saw that our final counter value was nondeterministic. It's not clear at first glance why this is. Our loop increments the counter at every step, so the counter should go up by one every time. If counter.increment() is called 200000 times, we'd expect the final value to be 200000. That expectation relies on counter.increment() being atomic, but that's not the case.\n",
    "\n",
    "Let's look at the internals of counter.increment(). counter.increment() is a method on the Counter class, and its definition looks like this:\n",
    "\n",
    "def increment(self):\n",
    "\n",
    "    old_count = self.count\n",
    "    \n",
    "    self.count = old_count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our counter.increment() method actually consists of a few lines of code, and it's very possible that the lines don't all execute one after another.\n",
    "\n",
    "Suppose we have two threads calling counter.increment(), and that our counter is currently at the value 100500. Thread A might call old_count = self.count, and then thread A's value for old_count is 100500. Now suppose thread B calls old_count = self.count, and then thread B's value for old_count is also 100500.\n",
    "\n",
    "Now, in any order, both thread A and thread B assign old_count + 1 to self.count. The counter's count property is now 100501, even though counter.increment() was called twice. This is not the behavior we want, and counter.increment() appears to be nonatomic.\n",
    "\n",
    "We can use locks to imitate atomicity. If we were to protect every call to counter.increment() with the same lock, then only one thread would be able to increment the counter at a time. Equivalently, we could make counter.increment() an atomic operation by wrapping every line in its definition with a lock. This is the more modular approach, because users of the Counter class won't have to remember to use a lock with every call to counter.increment()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter():\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.lock = threading.Lock()\n",
    "    def increment(self):\n",
    "        self.lock.acquire()\n",
    "        old_count = self.count\n",
    "        self.count = old_count + 1\n",
    "        self.lock.release()\n",
    "    def get_count(self):\n",
    "        return self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_up_100000(counter):\n",
    "    for i in range(100000):\n",
    "        counter.increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_trial():\n",
    "    counter = Counter()\n",
    "    count_thread1 = threading.Thread(target=count_up_100000, args=[counter])\n",
    "    count_thread2 = threading.Thread(target=count_up_100000, args=[counter])\n",
    "\n",
    "    count_thread1.start()\n",
    "    count_thread2.start()\n",
    "\n",
    "    count_thread1.join()\n",
    "    count_thread2.join()\n",
    "\n",
    "    final_count = counter.get_count()\n",
    "    return final_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "200000\n",
      "200000\n"
     ]
    }
   ],
   "source": [
    "trial1 = conduct_trial()\n",
    "print(trial1)\n",
    "trial2 = conduct_trial()\n",
    "print(trial2)\n",
    "trial3 = conduct_trial()\n",
    "print(trial3)                                 \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen some of the problems that parallel processing can introduce, such as nonatomicity and nondeterminism. In data science, it's important to maintain the integrity of our data, and a multithreaded environment is no exception. By using tools like locks to enforce atomicity and determinism, we can protect resources shared between threads, and ensure that delegating tasks between threads doesn't introduce unexpected bugs into our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
